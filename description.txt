This project implements a custom RNN-based attention encoder-decoder model for Urdu-to-English machine translation using PyTorch. The dataset comprises parallel Urdu-English sentences, split into training, validation, and test sets. The model is designed without using pre-built RNN libraries, adhering to a fully manual implementation of the architecture.

Key Features
Custom RNN Model: Encoder-decoder structure with an attention mechanism.
Manual Attention Mechanism: Designed from scratch for efficient context handling.
Dataset Handling: Combines .dev and .devtest files for sentence-aligned data splitting.
Evaluation: BLEU score calculated using Moses' multi-bleu.perl script.
Results Visualization: Includes graphs of training/validation loss and BLEU scores.
Repository Contents
Code: Implementation of the custom model, training, evaluation, and preprocessing scripts.
Dataset: Preprocessed data ready for training and testing.
Results: Translation outputs, BLEU scores, and comparative evaluation.
Documentation: Detailed comments and instructions for replication.
Bonus Features
LSTM-based model implementation for improved performance (optional).